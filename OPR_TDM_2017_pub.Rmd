---
title: "OPR_TDM_2017"
author: "BS"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Word clouds
Word clouds based on free text comments: 

* frequency of words (while stop-words have been taken out), 
* based on negative vs. positive sentiments 

```{r echo=FALSE, cache=TRUE, message=FALSE}
library(tidytext)
library(tidyverse)
library(wordcloud)

# Question from Open Peer Review Survey - OpenAIRE 2017
#D202_01 [01]
#Free text
#[D203] Text Input
#General Comment
#"Do you have any other comments?"

#D203_01 [01]
#Free text

# Load the data
# read data file, ignore line 2 (contains details on the variables)
all_content = readLines("https://zenodo.org/record/439531/files/openaire_survey_open_peer_review_2016.csv")
skip_second = all_content[-2]
OPRSdata <- read.csv(textConnection(skip_second), header=TRUE, sep=";", na.strings=c("-9"), stringsAsFactors=TRUE)
OPRcomments <- OPRSdata %>% filter(!(D203_01 %in% c("", " ", "-", ".", "xxx", "No", "no", "NO", "NO.", "No.", "no.", "No!", "No, please", "No, I don't", "No. Thanks", "no ,thans.", "nope", "not now", "Nope", "None", "None.", "NONE", "none", NA, "N/A", "N/A.", "n/a", "NA", "Nil", "nil", "NIL", "Thanks", "Not", "nothing, thanks", "no, Thanks", "No, I have not.", "No this time", "No other comments.", "no other comments", "No other comments.", "I no comment.", "No comments", "None at this time", "NO_I do not have others.", "I don't have.", "no<br>", "No, I don't.", "Nothing", "No, I have not. ", "best success!", "thanks", "Not at this point."))) %>% select(CASE, DG04, DG06_01:DG06_05, D203_01)

# Look into free text comments D202_01 from OpenAIRE OPR survey
data(stop_words)
OPRcmts <- data_frame(line = 1:length(OPRcomments$D203_01), text = gsub("\r?\n|\r|<br>", "", as.character(OPRcomments$D203_01)))
OPRC <- OPRcmts %>% unnest_tokens(word, text) %>% # anti_join(stop_words)
    filter(!word %in% stop_words$word)

# word cloud negative vs. positive words 
# throws warnings as several words do not fit into the plot
library(reshape2)
#png("wordcloud_packages.png", width=12,height=8, units='in', res=300)
OPRC %>% inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("#F8766D", "#00BFC4"), scale = c(4, 0.1), max.words = 26, random.order = FALSE)

# word with bigrams > filter by not in stopwords on word2 > multiply sentiment by (-1) if the stop word in word2 is in c("no", "not") > summarize sentiment per line as above
# leave out combinations like "single blind", "double blind" etc.
OPRbigrams_sent <- OPRcmts %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% setdiff(stop_words$word, c("no", "not")),
         !word2 %in% union(stop_words$word, c("blind"))) 

# rename second word variable into standard variable for join
OPRbigrams_sent <- rename(OPRbigrams_sent, word = word2) 
# inner join with sentiment library afinn by variable word
ORPbigrams_safinn <- OPRbigrams_sent %>% inner_join(get_sentiments("afinn")) 
# change the sentiment for all bigrams which start with no, not
for (i in 1 : nrow(ORPbigrams_safinn)){
    if (ORPbigrams_safinn$word1[i] %in% c("no", "not")){
        ORPbigrams_safinn$score[i] <- (-1) * ORPbigrams_safinn$score[i]
    }
}
# summarize sentiments by response 
safinn <- ORPbigrams_safinn %>% group_by(index = line) %>% 
    summarise(sentiment = sum(score)) %>% 
    mutate(method = "AFINN")
safinn %>% count(sentiment < 0)
#1           FALSE   149
#2            TRUE   166

safinn %>% count(sentiment >= 0)

# plot the summarized sentiments
safinn %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +  ggtitle("Comments on OPR: Summarized sentiments") + 
  facet_wrap(~method, ncol = 1, scales = "free_y")

```

The last question of the survey invited participants to provide additional views on (open) peer review but also general comments on the design of the survey. We assess these responses regarding the general sentiment which was expressed by applying methods as provided by the tidytext R library (Robinson & Silge, 2016). 

We consider all bigrams based on the free text comments. Based on the AFINN sentiment lexicon (created and maintained by Finn Årup Nielsen, available via R's tidytext library) we assign sentiment values to the second word of all bigrams. As the word "blind" is coded as negative in the AFINN lexicon we leave out combinations in which "blind" is the second word. Moreover, we change the direction of the sentiment if the first word indicates a negation ("no", "not"). These values are then summarised to a sentiment score per response (cf. Figure XX below). Overall, slightly more negative (52.7%, 166 out of 315 responses) than positive comments (47.3%, 149 responses) were provided. In addition, there were more than twice as many strongly negative ones than strongly positive ones (`r safinn %>% filter(sentiment < -4) %>% nrow()` vs. `r safinn %>% filter(sentiment > 4) %>% nrow()` comments with score less or equal to -5 resp. larger or equal than 5). 

List of responses with strongly positive vs. strongly negative sentiment score
```{r echo=FALSE, cache=TRUE}
safinn %>% filter(sentiment < -4)
safinn %>% filter(sentiment > 4)
```

###References 

* Finn Årup Nielsen (2011). AFINN. Version AFINN-111. Available at: http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010
* David Robinson, Julia Silge (2016). tidytext. R library. Version 0.1.2. Available at: https://cran.r-project.org/web/packages/tidytext/